{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Capstone_Project_ImageClassification_Transfer_learning-Copy1.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk6k9ywuzIZK"
      },
      "source": [
        "# Cassava Leaf Classification | Artificial Intelligence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6JEPMvKzIZR"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpTEIzLGzIZS"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from efficientnet.keras import EfficientNetB3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f30BZOgLzIZV"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFWL9Z1kzIZW"
      },
      "source": [
        "train_dir = 'cassava-leaf-disease-classification/train_images'\n",
        "test_dir = 'cassava-leaf-disease-classification/test_images' \n",
        "train_names = pd.read_csv('cassava-leaf-disease-classification/train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivJOAVUazIZW",
        "outputId": "14fa7d6b-bcf4-4b7a-ec09-e1d68eb61a17"
      },
      "source": [
        "train_names['label'] = train_names['label'].apply(str)\n",
        "train_names.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000015157.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000201771.jpg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100042118.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000723321.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000812911.jpg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         image_id label\n",
              "0  1000015157.jpg     0\n",
              "1  1000201771.jpg     3\n",
              "2   100042118.jpg     1\n",
              "3  1000723321.jpg     1\n",
              "4  1000812911.jpg     3"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ5tTz1vzIZY",
        "outputId": "76d9ad00-a0d2-478c-f471-56dcd6e4eb0c"
      },
      "source": [
        "print(len(train_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUQx0R09zIZZ"
      },
      "source": [
        "## Plot the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyBpEbrhzIZa"
      },
      "source": [
        "batch_size = 32\n",
        "img_height = 600\n",
        "img_width = 800\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWo6b6KRzIZc"
      },
      "source": [
        "## Constructing the train generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYFiKC-lzIZd"
      },
      "source": [
        "# Performing on the fly image augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255.,shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jGkJZuNzIZe"
      },
      "source": [
        "We've applied feature scaling,image augmentation and then split the train set into 2 partitions one for training and the other for validation just by specifying the argument validation_split=0.2 which splits the dataset into to 2 sets where the validation set will have 20% of the total images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JbR6m3izIZf",
        "outputId": "3df12403-76cb-4144-fd10-9803bc440b2f"
      },
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "dataframe = train_names,\n",
        "directory = train_dir,\n",
        "x_col = \"image_id\",\n",
        "y_col = \"label\",\n",
        "subset = \"training\",\n",
        "batch_size = batch_size,\n",
        "seed = 42,\n",
        "shuffle = True,\n",
        "class_mode = \"sparse\",\n",
        "target_size = (img_height, img_width))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 17118 validated image filenames belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRE0bo7jzIZf",
        "outputId": "60dbf6c0-77cc-4c9b-8b81-5b02015f8aef"
      },
      "source": [
        "valid_generator = train_datagen.flow_from_dataframe(\n",
        "dataframe = train_names,\n",
        "directory = train_dir,\n",
        "x_col = \"image_id\",\n",
        "y_col = \"label\",\n",
        "subset = \"validation\",\n",
        "batch_size = batch_size,\n",
        "seed =42,\n",
        "shuffle = True,\n",
        "class_mode =\"sparse\",\n",
        "target_size = (img_height,img_width)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4279 validated image filenames belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-kLgFrVzIZg"
      },
      "source": [
        "## Iterating Over Data and Plotting it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvIDIZbizIZg"
      },
      "source": [
        "## Now the data and labels are together!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDHHtwObzIZh"
      },
      "source": [
        "base_model = keras.applications.Xception(\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(img_height, img_width, 3),\n",
        "    include_top=False)  # Do not include the ImageNet classifier at the top."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prUuPi6ezIZh"
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpwS8dmOzIZh"
      },
      "source": [
        "inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "\n",
        "x = base_model(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = keras.layers.Dense(1024,activation=\"relu\")(x)\n",
        "x = keras.layers.Dense(128,activation=\"relu\")(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(5,activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "checkpoint_filepath = 'model/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSqBfL4lzIZi",
        "outputId": "534dbfba-5049-4ae9-c029-ce483f1481c5"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 600, 800, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 19, 25, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 23,091,501\n",
            "Trainable params: 2,230,021\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "MO9KLij_zIZi",
        "outputId": "2eeaeb29-931e-404f-e694-b74f38c3e32f"
      },
      "source": [
        "model.fit(train_generator, epochs=10, validation_data=valid_generator, callbacks=[model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "535/535 [==============================] - 7016s 13s/step - loss: 0.7709 - accuracy: 0.7121 - val_loss: 0.6686 - val_accuracy: 0.7432\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 7008s 13s/step - loss: 0.6662 - accuracy: 0.7545 - val_loss: 0.6461 - val_accuracy: 0.7539\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 7019s 13s/step - loss: 0.6288 - accuracy: 0.7657 - val_loss: 0.6334 - val_accuracy: 0.7595\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 7432s 14s/step - loss: 0.6035 - accuracy: 0.7789 - val_loss: 0.6263 - val_accuracy: 0.7677\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 7854s 15s/step - loss: 0.5783 - accuracy: 0.7886 - val_loss: 0.5850 - val_accuracy: 0.7829\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 7868s 15s/step - loss: 0.5711 - accuracy: 0.7912 - val_loss: 0.5930 - val_accuracy: 0.7806\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 7871s 15s/step - loss: 0.5583 - accuracy: 0.7941 - val_loss: 0.6217 - val_accuracy: 0.7721\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 7784s 15s/step - loss: 0.5422 - accuracy: 0.8020 - val_loss: 0.5736 - val_accuracy: 0.7864\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 7050s 13s/step - loss: 0.5297 - accuracy: 0.8091 - val_loss: 0.6002 - val_accuracy: 0.7815\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 7068s 13s/step - loss: 0.5257 - accuracy: 0.8083 - val_loss: 0.5942 - val_accuracy: 0.7864\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7b9c410b38>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    }
  ]
}